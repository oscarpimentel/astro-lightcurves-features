{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # or just install the module\n",
    "sys.path.append('../../fuzzy-tools') # or just install the module\n",
    "sys.path.append('../../astro-lightcurves-handler') # or just install the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['method=spm-mcmc-estw~train_mode=r~fats_mode=all',\n",
       " 'method=spm-mcmc-fstw~train_mode=s~fats_mode=all',\n",
       " 'method=bspline-fstw~train_mode=r+s~fats_mode=all',\n",
       " 'method=linear-fstw~train_mode=r+s~fats_mode=all',\n",
       " 'method=spm-mcmc-estw~train_mode=r+s~fats_mode=all',\n",
       " 'method=spm-mcmc-fstw~train_mode=r+s~fats_mode=all',\n",
       " 'method=bspline-fstw~train_mode=s~fats_mode=all',\n",
       " 'method=linear-fstw~train_mode=s~fats_mode=all',\n",
       " 'method=spm-mcmc-estw~train_mode=s~fats_mode=all']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from lcfats.utils import get_model_names\n",
    "\n",
    "rootdir = '../save'\n",
    "set_name = 'test'\n",
    "method = 'spm-mcmc-estw'\n",
    "cfilename = f'survey=alerceZTFv7.1~bands=gr~mode=onlySNe~method={method}'\n",
    "kf = '.'\n",
    "\n",
    "model_names = get_model_names(rootdir, cfilename, kf, set_name)\n",
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import fuzzytools.files as ftfiles\n",
    "import fuzzytools.strings as ftstrings\n",
    "from fuzzytools.datascience.cms import ConfusionMatrix\n",
    "from fuzzytools.matplotlib.cm_plots import plot_custom_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzytools.datascience.xerror import XError\n",
    "from IPython.display import display\n",
    "from fuzzytools.strings import latex_bf_alphabet_count\n",
    "from fuzzytools.latex.latex_tables import LatexTable\n",
    "from fuzzytools.matplotlib.utils import save_fig\n",
    "import fuzzytools.strings as strings\n",
    "\n",
    "methods = [\n",
    "    'spm-mcmc-estw',\n",
    "    'spm-mcmc-fstw',\n",
    "    'linear-fstw',\n",
    "    'bspline-fstw',\n",
    "    ]\n",
    "\n",
    "RANDOM_STATE = None\n",
    "set_name = 'test'\n",
    "kf = '.'\n",
    "thday = 100\n",
    "\n",
    "for model_name in model_names:\n",
    "    model_name_d = strings.get_dict_from_string(model_name)\n",
    "    method = model_name_d['method']\n",
    "    load_roodir = f'../save/{model_name}/survey=alerceZTFv7.1~bands=gr~mode=onlySNe~method={method}'\n",
    "    print(load_roodir)\n",
    "    files, files_ids, kfs = ftfiles.gather_files_by_kfold(load_roodir, kf, set_name,\n",
    "        fext='d',\n",
    "        imbalanced_kf_mode='oversampling', # error oversampling\n",
    "        random_state=RANDOM_STATE,\n",
    "        )\n",
    "    \n",
    "    print(f'{files_ids}({len(files_ids)}#)')\n",
    "    if len(files)==0:\n",
    "        continue\n",
    "\n",
    "    class_names = files[0]()['class_names']\n",
    "    features = files[0]()['features']\n",
    "    rank = files[0]()['rank']\n",
    "    for f in features:\n",
    "        #print(f)\n",
    "        pass\n",
    "    thdays = files[0]()['thdays']\n",
    "    thday = thdays[np.argmin((np.array(thdays)-thday)**2)]\n",
    "\n",
    "    xe_dict = {}\n",
    "    for metric_name in ['recall', 'f1score']:\n",
    "        xe_metric = XError([f()['thdays_class_metrics_df'].loc[f()['thdays_class_metrics_df']['_thday']==thday][f'b-{metric_name}'].item() for f in files])\n",
    "        xe_dict[f'b-{metric_name}'] = xe_metric\n",
    "\n",
    "    brecall_xe = xe_dict['b-recall']\n",
    "    bf1score_xe = xe_dict['b-f1score']\n",
    "\n",
    "    new_order_class_names = ['SNIa', 'SNIbc', 'SNIIbn', 'SLSN']\n",
    "    new_order_class_names = ['SNIa', 'SNIbc', 'SNII*', 'SLSN']\n",
    "    cm = ConfusionMatrix([f()['thdays_cm'][thday] for f in files], class_names)\n",
    "    cm.reorder_classes(new_order_class_names)\n",
    "    for c in new_order_class_names:\n",
    "        print(cm.get_diagonal_dict()[c].get_raw_repr(f'brf_{c}_tp'))\n",
    "        pass\n",
    "    true_label_d = {c:f'({k}#)' for c,k in zip(class_names, np.sum(files[0]()['thdays_cm'][thday], axis=1))}\n",
    "\n",
    "    rank = files[0]()['rank'] # just show one\n",
    "    rank.names = ['Feature name=\\\\verb+'+n+'+' for n in rank.names]\n",
    "    rank.values = [v*100 for v in rank.values]\n",
    "    rank_df = rank.get_df()\n",
    "    latex_table = LatexTable(rank_df,\n",
    "        label='tab:brf_ranking',\n",
    "        )\n",
    "    #display(rank_df)\n",
    "    #print(latex_table)\n",
    "\n",
    "    ### plot cm\n",
    "    train_mode = model_name_d['train_mode']\n",
    "    model_name = ftstrings.get_formated_method('BRF', {\n",
    "        'training-set':f'[{train_mode}]',\n",
    "        'method':None if train_mode=='r' else method,\n",
    "        '#features':len(features),\n",
    "        })\n",
    "    title = ''\n",
    "    title += f'{latex_bf_alphabet_count(0)} {model_name}'+'\\n'\n",
    "    title += f'b-Recall={brecall_xe}; b-$F_1$score={bf1score_xe}'+'\\n'\n",
    "    title += f'th-day={thday:.0f} [days]'+'\\n'\n",
    "    fig, ax = plot_custom_confusion_matrix(cm,\n",
    "        title=title[:-1],\n",
    "        figsize=(6,5),\n",
    "        dpi=200,\n",
    "        true_label_d=true_label_d,\n",
    "        lambda_c=lambda x:x.replace('*', ''),\n",
    "        )\n",
    "    save_fig(fig, f'../temp/cms_a.pdf', closes_fig=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "../save/method=spm-mcmc-estw~train_mode=r~fats_mode=all/survey=alerceZTFv7.1~bands=gr~mode=onlySNe~method=spm-mcmc-estw\n",
      "['0@id=1000c0', '0@id=1000c1', '0@id=1001c0', '0@id=1001c1', '0@id=1002c0', '0@id=1002c1', '0@id=1003c0', '0@id=1003c1', '0@id=1004c0', '0@id=1004c1', '0@id=1005c0', '0@id=1005c1', '1@id=1000c0', '1@id=1000c1', '1@id=1001c0', '1@id=1001c1', '1@id=1002c0', '1@id=1002c1', '1@id=1003c0', '1@id=1003c1', '1@id=1004c0', '1@id=1004c1', '1@id=1005c0', '1@id=1005c1', '2@id=1000c0', '2@id=1000c1', '2@id=1001c0', '2@id=1001c1', '2@id=1002c0', '2@id=1002c1', '2@id=1003c0', '2@id=1003c1', '2@id=1004c0', '2@id=1004c1', '2@id=1005c0', '2@id=1005c1', '3@id=1000c0', '3@id=1000c1', '3@id=1001c0', '3@id=1001c1', '3@id=1002c0', '3@id=1002c1', '3@id=1003c0', '3@id=1003c1', '3@id=1004c0', '3@id=1004c1', '3@id=1005c0', '3@id=1005c1', '4@id=1000c0', '4@id=1000c1', '4@id=1001c0', '4@id=1001c1', '4@id=1002c0', '4@id=1002c1', '4@id=1003c0', '4@id=1003c1', '4@id=1004c0', '4@id=1004c1', '4@id=1005c0', '4@id=1005c1'](60#)\n",
      "../save/method=spm-mcmc-fstw~train_mode=s~fats_mode=all/survey=alerceZTFv7.1~bands=gr~mode=onlySNe~method=spm-mcmc-fstw\n",
      "['0@id=1000c0', '0@id=1000c1', '0@id=1001c0', '0@id=1001c1', '0@id=1002c0', '0@id=1002c1', '0@id=1003c0', '0@id=1003c1', '0@id=1004c0', '0@id=1004c1', '0@id=1005c0', '0@id=1005c1', '1@id=1000c0', '1@id=1000c1', '1@id=1001c0', '1@id=1001c1', '1@id=1002c0', '1@id=1002c1', '1@id=1003c0', '1@id=1003c1', '1@id=1004c0', '1@id=1004c1', '1@id=1005c0', '1@id=1005c1', '2@id=1000c0', '2@id=1000c1', '2@id=1001c0', '2@id=1001c1', '2@id=1002c0', '2@id=1002c1', '2@id=1003c0', '2@id=1003c1', '2@id=1004c0', '2@id=1004c1', '2@id=1005c0', '2@id=1005c1', '3@id=1000c0', '3@id=1000c1', '3@id=1001c0', '3@id=1001c1', '3@id=1002c0', '3@id=1002c1', '3@id=1003c0', '3@id=1003c1', '3@id=1004c0', '3@id=1004c1', '3@id=1005c0', '3@id=1005c1', '4@id=1000c0', '4@id=1000c1', '4@id=1001c0', '4@id=1001c1', '4@id=1002c0', '4@id=1002c1', '4@id=1003c0', '4@id=1003c1', '4@id=1004c0', '4@id=1004c1', '4@id=1005c0', '4@id=1005c1'](60#)\n",
      "../save/method=bspline-fstw~train_mode=r+s~fats_mode=all/survey=alerceZTFv7.1~bands=gr~mode=onlySNe~method=bspline-fstw\n",
      "['0@id=1000c0', '0@id=1000c1', '0@id=1001c0', '0@id=1001c1', '0@id=1002c0', '0@id=1002c1', '0@id=1003c0', '0@id=1003c1', '0@id=1004c0', '0@id=1004c1', '0@id=1005c0', '0@id=1005c1', '1@id=1000c0', '1@id=1000c1', '1@id=1001c0', '1@id=1001c1', '1@id=1002c0', '1@id=1002c1', '1@id=1003c0', '1@id=1003c1', '1@id=1004c0', '1@id=1004c1', '1@id=1005c0', '1@id=1005c1', '2@id=1000c0', '2@id=1000c1', '2@id=1001c0', '2@id=1001c1', '2@id=1002c0', '2@id=1002c1', '2@id=1003c0', '2@id=1003c1', '2@id=1004c0', '2@id=1004c1', '2@id=1005c0', '2@id=1005c1', '3@id=1000c0', '3@id=1000c1', '3@id=1001c0', '3@id=1001c1', '3@id=1002c0', '3@id=1002c1', '3@id=1003c0', '3@id=1003c1', '3@id=1004c0', '3@id=1004c1', '3@id=1005c0', '3@id=1005c1', '4@id=1000c0', '4@id=1000c1', '4@id=1001c0', '4@id=1001c1', '4@id=1002c0', '4@id=1002c1', '4@id=1003c0', '4@id=1003c1', '4@id=1004c0', '4@id=1004c1', '4@id=1005c0', '4@id=1005c1'](60#)\n",
      "../save/method=linear-fstw~train_mode=r+s~fats_mode=all/survey=alerceZTFv7.1~bands=gr~mode=onlySNe~method=linear-fstw\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from fuzzytools.files import load_pickle, save_pickle\n",
    "from fuzzytools.datascience.xerror import XError\n",
    "from fuzzytools.dataframes import DFBuilder\n",
    "from fuzzytools.latex.latex_tables import LatexTable\n",
    "from fuzzytools.files import save_pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import fuzzytools.matplotlib.fills as fills\n",
    "import fuzzytools.strings as ftstrings\n",
    "import fuzzytools.files as ftfiles\n",
    "import fuzzytools.matplotlib.colors as ftc\n",
    "\n",
    "DICT_NAME = 'thdays_class_metrics'\n",
    "dict_name = DICT_NAME\n",
    "RANDOM_STATE = None\n",
    "METRICS_D = {\n",
    "    f'aucroc':{'k':1, 'mn':'AUCROC'},\n",
    "    f'precision':{'k':1, 'mn':'Precision'},\n",
    "    f'recall':{'k':1, 'mn':'Recall'},\n",
    "    f'f1score':{'k':1, 'mn':'$F_1$score'},\n",
    "    f'aucpr':{'k':1, 'mn':'AUCPR'},\n",
    "    f'gmean':{'k':1, 'mn':'Gmean'},\n",
    "    f'accuracy':{'k':1, 'mn':'Accuracy'},\n",
    "    }\n",
    "\n",
    "metric_names = [\n",
    "    'precision',\n",
    "    'recall',\n",
    "    'f1score',\n",
    "    'aucroc',\n",
    "    'aucpr',\n",
    "    ]\n",
    "target_class = None\n",
    "metric_name = 'aucroc'\n",
    "figsize = (10,5)\n",
    "info_df = DFBuilder()\n",
    "colors = ftc.colors()\n",
    "fig, ax = plt.subplots(1, 1, figsize=figsize, dpi=200)\n",
    "for kmn,model_name in enumerate(model_names):\n",
    "    model_name_d = ftstrings.get_dict_from_string(model_name)\n",
    "    method = model_name_d['method']\n",
    "    load_roodir = f'../save/{model_name}/survey=alerceZTFv7.1~bands=gr~mode=onlySNe~method={method}'\n",
    "    print(load_roodir)\n",
    "    files, files_ids, kfs = ftfiles.gather_files_by_kfold(load_roodir, kf, set_name,\n",
    "        fext='d',\n",
    "        imbalanced_kf_mode='oversampling', # error oversampling\n",
    "        random_state=RANDOM_STATE,\n",
    "        )\n",
    "    \n",
    "    print(f'{files_ids}({len(files_ids)}#)')\n",
    "    if len(files)==0:\n",
    "        continue\n",
    "\n",
    "        \n",
    "    thdays = files[0]()['thdays']\n",
    "    thdays_computed_curves = []\n",
    "    metric_curves = []\n",
    "    for f in files:\n",
    "        thdays_computed_curves += [np.array(f()['thdays_computed'])]\n",
    "        if target_class is None:\n",
    "            metric_curve = f()[f'{dict_name}_df'][f'b-{metric_name}'].values\n",
    "            metric_curves += [metric_curve]\n",
    "        else:\n",
    "            metric_curve = f()[f'{dict_name}_cdf'][target_class][f'{metric_name}'].values\n",
    "            metric_curves += [metric_curve]\n",
    "    \n",
    "    color = colors[kmn]\n",
    "    label = f'{model_name}'\n",
    "    shadow_alpha = 0.1\n",
    "    std_prop = 1\n",
    "    linestyle = ':'\n",
    "    if model_name_d['train_mode']=='s':\n",
    "        linestyle = '--'\n",
    "    if model_name_d['train_mode']=='r+s':\n",
    "        linestyle = '-'\n",
    "    ax, new_x, median_y, yrange = fills.fill_beetween_mean_std(ax, thdays_computed_curves, metric_curves,\n",
    "        mean_kwargs={'color':color, 'alpha':1, 'linestyle':linestyle, 'marker':'D', 'markersize':8, 'markerfacecolor':'None', 'markevery':[0], 'zorder':-.5, 'label':label},\n",
    "        fill_kwargs={'color':color, 'alpha':shadow_alpha, 'lw':0, 'zorder':-.5},\n",
    "        returns_extras=True,\n",
    "        std_prop=std_prop,\n",
    "        )\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from fuzzytools.files import load_pickle, save_pickle\n",
    "from fuzzytools.datascience.xerror import XError\n",
    "from fuzzytools.dataframes import DFBuilder\n",
    "from fuzzytools.latex.latex_tables import LatexTable\n",
    "from fuzzytools.files import save_pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import fuzzytools.matplotlib.fills as fills\n",
    "\n",
    "METRICS_D = {\n",
    "    f'aucroc':{'k':1, 'mn':'AUCROC'},\n",
    "    f'precision':{'k':1, 'mn':'Precision'},\n",
    "    f'recall':{'k':1, 'mn':'Recall'},\n",
    "    f'f1score':{'k':1, 'mn':'$F_1$score'},\n",
    "    f'aucpr':{'k':1, 'mn':'AUCPR'},\n",
    "    f'gmean':{'k':1, 'mn':'Gmean'},\n",
    "    f'accuracy':{'k':1, 'mn':'Accuracy'},\n",
    "    }\n",
    "\n",
    "metric_names = [\n",
    "    'precision',\n",
    "    'recall',\n",
    "    'f1score',\n",
    "    'aucroc',\n",
    "    'aucpr',\n",
    "    ]\n",
    "\n",
    "curve_metric_name = 'aucroc'\n",
    "info_df = DFBuilder()\n",
    "for model_name in model_names:\n",
    "    model_name_d = strings.get_dict_from_string(model_name)\n",
    "    method = model_name_d['method']\n",
    "    load_roodir = f'../save/{model_name}/survey=alerceZTFv7.1~bands=gr~mode=onlySNe~method={method}'\n",
    "    print(load_roodir)\n",
    "    files, files_ids, kfs = ftfiles.gather_files_by_kfold(load_roodir, kf, set_name,\n",
    "        fext='d',\n",
    "        imbalanced_kf_mode='oversampling', # error oversampling\n",
    "        random_state=RANDOM_STATE,\n",
    "        )\n",
    "    \n",
    "    print(f'{files_ids}({len(files_ids)}#)')\n",
    "    if len(files)==0:\n",
    "        continue\n",
    "\n",
    "    for metric_name in metric_names:\n",
    "        print([f()['thdays_class_metrics_df'][f'b-{curve_metric_name}'].values for f in files])\n",
    "        assert 0\n",
    "        xe_metric = XError([f()['thdays_class_metrics_df'].loc[f()['thdays_class_metrics_df']['_thday']==thday][f'b-{metric_name}'].item() for f in files])\n",
    "        print(metric_name, xe_metric)\n",
    "        #xe_dict[metric_name] = xe_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from fuzzytools.files import load_pickle, save_pickle\n",
    "from fuzzytools.datascience.xerror import XError\n",
    "from fuzzytools.dataframes import DFBuilder\n",
    "from fuzzytools.latex.latex_tables import LatexTable\n",
    "from fuzzytools.files import save_pickle\n",
    "\n",
    "METRICS_D = {\n",
    "    f'aucroc':{'k':1, 'mn':'AUCROC'},\n",
    "    f'precision':{'k':1, 'mn':'Precision'},\n",
    "    f'recall':{'k':1, 'mn':'Recall'},\n",
    "    f'f1score':{'k':1, 'mn':'$F_1$score'},\n",
    "    f'aucpr':{'k':1, 'mn':'AUCPR'},\n",
    "    f'gmean':{'k':1, 'mn':'Gmean'},\n",
    "    f'accuracy':{'k':1, 'mn':'Accuracy'},\n",
    "    }\n",
    "\n",
    "metric_names = [\n",
    "    'precision',\n",
    "    'recall',\n",
    "    'f1score',\n",
    "    'aucroc',\n",
    "    'aucpr',\n",
    "    ]\n",
    "info_df = DFBuilder()\n",
    "train_configs = ['r', 's', 'r+s']\n",
    "for train_config in train_configs:\n",
    "    #aux_r = []\n",
    "    for method in methods:\n",
    "    #d = {}\n",
    "    #for metric in metric_names:\n",
    "    #mn = METRICS_D[metric]['mn']\n",
    "    load_roodir = f'../save/performance/exp=rf_eval~train_config={train_config}/survey=alerceZTFv7.1~bands=gr~mode=onlySNe~method={method}'\n",
    "    print(load_roodir)\n",
    "    try:\n",
    "        files, files_ids, kfs = ftfiles.gather_files_by_kfold(load_roodir, kf, set_name,\n",
    "            fext='d',\n",
    "            imbalanced_kf_mode='oversampling', # error oversampling\n",
    "            random_state=RANDOM_STATE,\n",
    "            )\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    print(f'{files_ids}({len(files_ids)}#)')\n",
    "    if len(files)==0:\n",
    "        continue\n",
    "    #xe_dict = {}\n",
    "    for metric_name in metric_names:\n",
    "        xe_metric = XError([f()['thdays_class_metrics_df'].loc[f()['thdays_class_metrics_df']['_thday']==thday][f'b-{metric_name}'].item() for f in files])\n",
    "        print(metric_name, xe_metric)\n",
    "        #xe_dict[metric_name] = xe_metric\n",
    "\n",
    "    #brecall_xe = xe_dict['b-recall']\n",
    "    #bf1score_xe = xe_dict['b-f1score']\n",
    "\n",
    "    #features = files[0]()['features']\n",
    "    #metric_xe = XError([f()['metrics_dict'][metric]*dmetrics[metric]['k'] for f in files])\n",
    "    #d[mn] = metric_xe\n",
    "    #print(len(metric_xe))\n",
    "\n",
    "    #if not train_config=='r': # mean across methods in real case\n",
    "    #    info_df.append(f'synthetic-method={method} [{train_config}]', d)\n",
    "    #else:\n",
    "    #    aux_r.append(d)\n",
    "\n",
    "#if train_config=='r': # mean across methods in real case\n",
    " #   for r in aux_r:\n",
    "  #      print(r)\n",
    "   # new_d = {k:sum([r[k] for r in aux_r]) for k in d.keys()}\n",
    "    #info_df.append(f'synthetic-method=no-method [{train_config}]', new_d)\n",
    "    \n",
    "display(info_df())\n",
    "\n",
    "ttest_metric = 'b-AUCROC'\n",
    "info_df['synthetic-method=spm-mcmc-estw [r+s]'][ttest_metric].gt_ttest(info_df['synthetic-method=no-method [r]'][ttest_metric], verbose=1)\n",
    "\n",
    "\n",
    "latex_kwargs = {\n",
    "    'label':'tab:',\n",
    "    'bold_axis':'columns',\n",
    "}\n",
    "latex_table = LatexTable(info_df(), **latex_kwargs)\n",
    "print(latex_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
